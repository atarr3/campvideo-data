# campvideo-data
Replication data for ["Automated Coding of Political Campaign Advertisement Videos: An Empirical Validation Study"]() by Alexander Tarr, June Hwang, and Kosuke Imai.

## Table of Contents
1. [Overview](#Overview)
2. [Repository Layout](#Repository-Layout)
3. [Data](#Data)
4. [Installation](#Installation)
5. [Preprocessing the WMP Data](#Preprocessing-the-WMP-Data)
6. [Figure and Table Replication](#Figure-and-Table-Replication)
7. [Results Replication](#Results-Replication)
8. [Additional Notes](#Additional-Notes)

## Overview
Full replication of the results in the paper is a laborious process, involving significant setup and computation time on the part of the user. To simplify the procedure, we have split replication into two parts: [Feature Extraction](README-FE.md#Feature-Extraction) and [Validation](#Validation). For those seeking only to validate the results in the paper, it is **highly recommended** to ignore feature extraction and follow the steps for validation, which uses pre-computed features from the feature extraction step.

We provide instructions for replicating the [Validation](#Validation) step in this document, while instructions for replicating feature extraction are found in [README-FE.md](README-FE.md).

## Repository Layout
This repository is split into several folders: ``data``, ``figs``, ``results``, ``scripts`` and ``tables``.
- ``data``: This folder contains all data needed to perform both feature extraction and validation.
  * ``ids``: Numpy vectors for face encodings corresponding to Senate candidates in the 2012 and 2014 elections.
  * ``intermediate``: Extracted feature data for each YouTube video in the study. This data includes Numpy vectors for audio features, keyframe indices, auto-generated transcripts, and detected image text. Data in this folder is created in the [Feature Extraction](README-FE.md/#Feature-Extraction) step.
  * ``matches``: CSV and JSON files containing information about matches between CMAG videos and YouTube videos. These files are used for computing coverage tables and preprocessing the raw WMP data.
  * ``mturk``: CSV files containing results from the Amazon Mechanical Turk studies.
  * ``validation``: CSV files containing results from the validation analyses discussed in the appendix.
  * ``videos``: MP4 files corresponding to YouTube videos used in the study. Data in this folder is used in the [Feature Extraction](README-FE.md#Feature-Extraction) step.
  * ``wmp``: DTA files containing WMP/CMAG data. Data in this folder is used in the [Validation](#Validation) step.
- ``figs``: PDFs for figures generated by the code that are displayed in the paper.
- ``results``: CSV files containing predicted labels for tasks studied in the paper. There are also raw text files showing general statistics about the performance of our methods that are discussed in the main text of the paper.
- ``scripts``: All code needed to generate data, extract features, validate results, and create figures and tables.
- ``tables``: Raw text files showing confusion matrices and coverage tables corresponding to tables in the paper.

## Data
Replication in the [Feature Extraction](README-FE.md#Feature-Extraction) step requires the human-coded labels provided by WMP. Unfortunately, we cannot share this dataset publicly. The WMP data can be purchased [here](https://mediaproject.wesleyan.edu/dataaccess/). Our study used the 2012 Presidential, 2012 Non-Presidential, and 2014 data. The data is distributed across 7 Stata files, one for each year and race type (House, Senate, Governor, President). These files should be placed in the [``data/wmp``](data/wmp) folder.

# Validation
## Installation
Recreating all figures, tables and results requires working installations
- [Python](https://www.python.org/downloads/), version 3.9 or greater. We recommend using the [Anaconda distribution](https://www.anaconda.com/products/distribution) if unfamiliar with Python.
- [R](https://cran.r-project.org/src/base/R-4/), version 4.0 or greater

All code in this repo was tested under Python version 3.9.7 and R version 4.0.5 on a Windows 10 machine. 

### Prequisites
#### CMake and C++ Compiler
Installing the required Python packages requires both CMake and a C++ compiler. For macOS users, these requirements are normally already satisfied.
- C++ Compiler: Windows users should install a C++ compiler from [Microsoft Visual Studio Community Edition](https://visualstudio.microsoft.com/downloads/). Be sure to install the latest x86/x64 C++ build tools and the appropriate Windows SDK for your Windows platform. For example, a Windows 10 user would install
  - MSVC v143 - VS 2022 C++ x64/x86 build tools (Latest)
  - Windows 10 SDK (Latest version)
- CMake: Install CMake via the command

  ```sh
  pip install cmake
  ```

#### CUDA and cuDNN
We **strongly recommended** that users with access to a dedicated GPU for computing install 
- [CUDA](https://docs.nvidia.com/cuda/index.html#installation-guides)
- [cuDNN](https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html). 
 
Without GPU support, results in [``results``](results) will differ, and performance will be much slower.

### Python Dependencies
#### dlib
Windows users must build and install the ``dlib`` package from its [GitHub repository](https://github.com/davisking/dlib). After cloning the repository, navigate to the folder and enter

```sh
python setup.py install --no DLIB_GIF_SUPPORT
```

macOS users may skip this step.

#### Other packages
The remaining Python package dependencies can be installed by installing the project-related [``campvideo``](https://test.pypi.org/project/campvideo/) package. Both Windows and macOS users should install this package via

```sh
pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple campvideo
```

### R Dependencies
All R code uses the following packages: ``dplyr, here, lme4, quanteda, quanteda.sentiment, readstata13, readtext, stargazer, xtable``, most of which can be installed from within the R environment via

```r
install.packages("<PACKAGE_NAME>")
```

``quanteda.sentiment`` is not available on CRAN and must be installed via

```r
devtools::install_github("quanteda/quanteda.sentiment")
```

### spaCy Model Download
The ``spacy`` text modeling package requires downloading a model. After installing the Python packages, enter the following command:

```sh
python -m spacy download en_core_web_md
```    
    
## Preprocessing the WMP Data
Before any results can be produced, the WMP data must be cleaned. After placing the Stata files into [``data/wmp``](data/wmp), clean the data via

```sh
Rscript scripts/preprocess_CMAG.R
```

This file may also be sourced from within an IDE, such as RStudio. Be sure to set the working directory to repo folder, [``campvideo-data``](https://github.com/atarr3/campvideo-data). After running, a file called ``wmp_final.csv`` should be created in [``data/wmp``](data/wmp).

## Figure and Table Replication
All figure and table replication scripts are in the [``scripts``](scripts) folder. The files are named after the figures and tables they replicate. For example, [``figure5.R``](scripts/figure5.R) recreates Figure 5, and [``tableS14-6.py``](scripts/tableS14-6.py) recreates Appendix Table S14.6. Note that some scripts create multiple tables or figures.

The full list of figures and tables and associated replication code is given below.

| Result        | Language | Script                                                       |
| :------------ | :------- | :----------------------------------------------------------- |
| Figure 5      | R        | [``figure5.R``](scripts/figure5.R)                           |
| Figure 8      | R        | [``figure8_S14-9_S14-10.R``](scripts/figure8_S14-9_S14-10.R) |
| Figure S7.4   | Python   | [``figureS7-4.py``](scripts/figureS7-4.py)                   |
| Figure S13.8  | Python   | [``figureS13-8.py``](scripts/figureS13-8.py)                 |
| Figure S14.9  | R        | [``figure8_S14-9_S14-10.R``](scripts/figure8_S14-9_S14-10.R) |
| Figure S14.10 | R        | [``figure8_S14-9_S14-10.R``](scripts/figure8_S14-9_S14-10.R) |
| Table 1       | R        | [``table1.R``](scripts/table1.R)                             |
| Table 2       | Python   | [``table2.py``](scripts/table2.py)                           |
| Table 3       | Python   | [``table3.py``](scripts/table3.py)                           |
| Table 4       | Python   | [``table4.py``](scripts/table4.py)                           |
| Table 5       | Python   | [``table5.py``](scripts/table5.py)                           |
| Table 6       | Python   | [``table6.py``](scripts/table6.py)                           |
| Table S1.1    | R        | [``tableS1-1.R``](scripts/tableS1-1.R)                       |
| Table S14.1   | Python   | [``tableS14-1.py``](scripts/tableS14-1.py)                   |
| Table S14.3   | R        | [``tableS14-3.R``](scripts/tableS14-3.R)                     |
| Table S14.6   | Python   | [``tableS14-6.py``](scripts/tableS14-6.py)                   |
| Table S14.8   | R        | [``tableS14-8.R``](scripts/tableS14-8.R)                     |

Python scripts can be executed via

```
python scripts/<SCRIPT>
```

and R scripts can be executed via

```
Rscript scripts/<SCRIPT>
```

where ``<SCRIPT>`` is given by the name in the "Script" column in the table above.

## Results Replication
The replication code for the figures and tables relies on pre-computed results in the [``results``](results) folder. The CSV files in this folder contain the predicted labels and some feature information. The following table describes the different results files, the associated classification tasks, the script for generating the results file, and the Figures and Tables which depend on those results.

| Results File                                               | Classification Task          | Script                                                     |  Figure and Table Dependencies                              |
| :--------------------------------------------------------- | :--------------------------- | :--------------------------------------------------------- | :---------------------------------------------------------- |
| [``summary_results.csv``](results/summary_results.csv)     | Video Summarization          | [``summary_validation.py``](scripts/summary_validation.py) | Figure S7.4                                                 |
| [``mentions_results.csv``](results/mentions_results.csv)   | Issue/Opponent Mentions      | [``text_validation.py``](scripts/text_validation.py)       | Figure 5, Table 2, Table 3                                  |
| [``facerec_results.csv``](results/facerec_results.csv)     | Face Recognition             | [``facerec_validation.py``](scripts/facerec_validation.py) | Figure S13.8, Table 4                                       |
| [``mood_results.csv``](results/mood_results.csv)           | Music Mood Classification    | [``mood_validation.py``](scripts/mood_validation.py)       | Figure 8, Figure S14.9, Figure S14.10, Table 5, Table S14.1 |
| [``negativity_results.csv``](results/mentions_results.csv) | Ad Negativity Classification | [``text_validation.py``](scripts/text_validation.py)       | Table 6, Table S14.3, Table S14.6                           | 

These scripts can be executed via

```
python scripts/<SCRIPT>
```

where ``<SCRIPT>`` is given by the name in the "Script" column in the table above.

In addition to the CSV files, these scripts also produces raw text files containing various performance metrics reported in the main text. Like the figures and tables, these files rely on data in the CSV files. These files can be recreated without overwriting the CSV files via

```
python scripts/<SCRIPT> --no-calculate
```

where ``<SCRIPT>`` is given by the name in the "Script" column in the table above.

## Additional Notes
- Face recognition results will differ substantially if CUDA and cuDNN are not installed. This is due to the ``face_recognition`` package using differen face detection models in these scenarios.
- Recreating the figures and tables using pre-computed results only takes a few minutes. Recreating the results CSV files is much more time-consuming due to extensive model training and file I/O. Expect this step to take upwards of a day.
- Exact replication for label prediction is only guaranteed for the models we train. Face recognition, image text recognition, and speech transcription all rely on external models which we have no control over. Future updates to these models may lead to slightly different results than those given in the paper.
- 'File not found' errors are likely due to issues with working directory. All code assumes this repo, `campvideo-data`, is the working directory.
